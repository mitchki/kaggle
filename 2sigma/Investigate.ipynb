{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmitchell/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"~/data/TwoSigma/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "\n",
    "#pd.read_json(\"~/data/TwoSigma/train.json\")\n",
    "#pd.read_json(\"/home/kmitchell/data/TwoSigma/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=42, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10                                                       []\n",
       "10000     [Doorman, Elevator, Fitness Center, Cats Allow...\n",
       "100004    [Laundry In Building, Dishwasher, Hardwood Flo...\n",
       "100007                            [Hardwood Floors, No Fee]\n",
       "100013                                            [Pre-War]\n",
       "100014                                                   []\n",
       "100016    [prewar, elevator, Dogs Allowed, Cats Allowed,...\n",
       "100020    [Doorman, Elevator, Pre-War, Terrace, Laundry ...\n",
       "100026    [Cats Allowed, Dogs Allowed, Elevator, Laundry...\n",
       "100027                        [Dishwasher, Hardwood Floors]\n",
       "100030                                                   []\n",
       "10004     [prewar, dishwasher, HIGHRISE, ROOFDECK, EAT I...\n",
       "100044     [Doorman, Elevator, Laundry in Building, No Fee]\n",
       "100048    [Swimming Pool, Doorman, Fitness Center, No Fe...\n",
       "10005     [Elevator, Multi-Level, Laundry in Building, D...\n",
       "100051    [Doorman, Elevator, Fitness Center, Laundry in...\n",
       "100052                                    [Hardwood Floors]\n",
       "100053    [prewar, LOWRISE, EAT IN KITCHEN, SIMPLEX, HAR...\n",
       "100055                 [No Fee, Cats Allowed, Dogs Allowed]\n",
       "100058                         [Cats Allowed, Dogs Allowed]\n",
       "100062     [Doorman, Elevator, Dishwasher, Hardwood Floors]\n",
       "100063    [Elevator, Central A/C, Walk in Closet(s), Par...\n",
       "100065                         [Cats Allowed, Dogs Allowed]\n",
       "100066    [Doorman, Fitness Center, Pool, Elevator, Publ...\n",
       "10007     [Balcony, Doorman, Elevator, Fitness Center, T...\n",
       "100071    [Roof Deck, Dining Room, Balcony, Doorman, Ele...\n",
       "100075                [Dishwasher, Hardwood Floors, No Fee]\n",
       "100076    [Roof Deck, Doorman, Elevator, Laundry in Buil...\n",
       "100079                                                   []\n",
       "100081    [Doorman, Elevator, Fitness Center, Pre-War, L...\n",
       "                                ...                        \n",
       "99915     [Swimming Pool, Doorman, Fitness Center, Dogs ...\n",
       "99917     [Cats Allowed, Dogs Allowed, Doorman, Elevator...\n",
       "99919     [Elevator, Laundry in Building, Laundry in Uni...\n",
       "99921                          [Furnished, Laundry In Unit]\n",
       "99923        [Doorman, Pre-War, Dogs Allowed, Cats Allowed]\n",
       "99924     [Doorman, Laundry in Building, Laundry in Unit...\n",
       "99931                          [Dogs Allowed, Cats Allowed]\n",
       "99933     [Roof Deck, Dining Room, Doorman, Elevator, Fi...\n",
       "99935                                                    []\n",
       "99937     [Pre-War, Laundry in Building, Dishwasher, Har...\n",
       "9994         [Doorman, Pre-War, Dogs Allowed, Cats Allowed]\n",
       "99953     [Doorman, Elevator, Furnished, Pre-War, Dishwa...\n",
       "99956     [Common Outdoor Space, Cats Allowed, Dogs Allo...\n",
       "99960                                     [Hardwood Floors]\n",
       "99961     [Doorman, Elevator, Laundry in Building, Dishw...\n",
       "99964      [Loft, Multi-Level, Dishwasher, Hardwood Floors]\n",
       "99965     [Swimming Pool, Dining Room, Doorman, Elevator...\n",
       "99966     [Roof Deck, Doorman, Elevator, Fitness Center,...\n",
       "99979                                                    []\n",
       "99980     [Common Outdoor Space, Cats Allowed, Dogs Allo...\n",
       "99982     [Doorman, Elevator, Fitness Center, Laundry in...\n",
       "99984     [Elevator, Multi-Level, Dishwasher, Hardwood F...\n",
       "99986                           [Elevator, Hardwood Floors]\n",
       "99987                                          [Dishwasher]\n",
       "99988     [Cats Allowed, No Fee, Doorman, Elevator, Laun...\n",
       "9999      [Elevator, Laundry in Building, Laundry in Uni...\n",
       "99991     [Common Outdoor Space, Cats Allowed, Dogs Allo...\n",
       "99992     [Doorman, Elevator, Pre-War, Dogs Allowed, Cat...\n",
       "99993     [Doorman, Elevator, Pre-War, Dogs Allowed, Cat...\n",
       "99994                                     [Hardwood Floors]\n",
       "Name: features, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features \n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "# adding all these new features to use list #\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\", \"created_month\", \"created_day\", \"listing_id\", \"created_hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_df.pkl')\n",
    "test_df.to_pickle('test_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data frames created above and saved to pkl file\n",
    "pkl file loaded below and used for model building and evaluation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.iloc[:,5:15].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['features'] = train_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "test_df['features'] = test_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "print(train_df[\"features\"].head())\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "tr_sparse = tfidf.fit_transform(train_df[\"features\"])\n",
    "te_sparse = tfidf.transform(test_df[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = sparse.hstack([train_df[features_to_use], tr_sparse]).tocsr()\n",
    "test_X = sparse.hstack([test_df[features_to_use], te_sparse]).tocsr()\n",
    "\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_scores = []\n",
    "kf = model_selection.KFold(n_splits=7, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(range(train_X.shape[0])):\n",
    "        dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        print(cv_scores)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds, model = runXGB(train_X, train_y, test_X, num_rounds=400)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"xgb_starter2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
